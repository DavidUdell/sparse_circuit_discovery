## Key Params
# Throughout, leave out entries for None. Writing in `None` values will get
# you the string "None".
ACTS_LAYERS_SLICE: "3:5"
INIT_THINNING_FACTOR: 1.0
NUM_SEQUENCES_INTERPED: 1
THRESHOLD_EXP: 5.0

# Only pin single dims per layer.
DIMS_PINNED:

# Topk thresholds for gradient-based method.
NUM_DOWN_NODES: 10
NUM_UP_NODES: 10

# Here you can freely pin multiple dims per layer.
VALIDATION_DIMS_PINNED:
  1: [23433]
  2: [16869]
  3: [953, 10942, 14555]
  4: [7780, 312, 5030, 3888]
  5: [16123, 22045, 10603, 14829]
  6: [6565, 6210, 3290, 18557]
  7: [15755, 10605, 4330, 15608]
  8: [18895, 7521, 21283]
  9: [15232, 768, 5147]
  10: [6807, 9817, 10944]

#
## Main Config
# Model
# "EleutherAI/pythia-70m"
# "meta-llama/Llama-2-7b-hf"
# "meta-llama/Llama-2-70b-hf"
MODEL_DIR: "openai-community/gpt2"

# Prompt
PROMPT: "Copyright (C"

# Layers Slice to Cache Activations From
# Put a Python slice here, in str format. Put ":" to use data from all model
# layers.
# ACTS_LAYERS_SLICE: "4:6"

# Autoencoder Size
PROJECTION_FACTOR: 32

# Autoencoder Save Files
ENCODER_FILE: "resid_encoder.pt"
ENC_BIASES_FILE: "resid_enc_biases.pt"
DECODER_FILE: "resid_decoder.pt"
DEC_BIASES_FILE: "resid_dec_biases.pt"
ATTN_ENCODER_FILE: "attn_encoder.pt"
ATTN_ENC_BIASES_FILE: "attn_enc_biases.pt"
ATTN_DECODER_FILE: "attn_decoder.pt"
ATTN_DEC_BIASES_FILE: "attn_dec_biases.pt"
MLP_ENCODER_FILE: "mlp_encoder.pt"
MLP_ENC_BIASES_FILE: "mlp_enc_biases.pt"
MLP_DECODER_FILE: "mlp_decoder.pt"
MLP_DEC_BIASES_FILE: "mlp_dec_biases.pt"

# Other Save Files
PROMPT_IDS_FILE: "activations_prompt_ids.npy"
ACTS_DATA_FILE: "resid_acts_dataset.pt"
ATTN_DATA_FILE: "attn_acts_dataset.pt"
MLP_DATA_FILE: "mlp_acts_dataset.pt"
TOP_K_INFO_FILE: "resid_tokens.csv"
ATTN_TOKEN_FILE: "attn_tokens.csv"
MLP_TOKEN_FILE: "mlp_tokens.csv"
GRAPH_FILE: "cognition_graph.svg"
GRAPH_DOT_FILE: "cognition_graph.dot"
JACOBIANS_FILE: "jacobians_graph.svg"
JACOBIANS_DOT_FILE: "jacobians_graph.dot"
GRADS_FILE: "grads_graph.svg"
GRADS_DOT_FILE: "grads_graph.dot"

# Autoencoder Training
LAMBDA_L1: 1e-2
LEARNING_RATE: 3e-3
TRAINING_BATCH_SIZE: 8
NUM_WORKERS: 8
ACCUMULATE_GRAD_BATCHES: 4

# Cognition Graph
# Disable pinning to plot every ablation effect. Dims are pinned by setting a
# layer and dim index as keys and values.
LOGIT_TOKENS: 10
# INIT_THINNING_FACTOR: 0.01
# DIMS_PINNED:
# THRESHOLD: 5.0

# Validate Circuits
# VALIDATION_DIMS_PINNED:

#
## Stable Dev Constants
# `wandb` logging
WANDB_PROJECT: "sparse_circuit_discovery"
WANDB_ENTITY: "davidudell"

# Reproducibility
SEED: 0

# `collect_acts.py`
NUM_SEQUENCES_EVALED: 1000
MAX_SEQ_LEN: 100

# `train_autoencoder.py`
LOG_EVERY_N_STEPS: 1
EPOCHS: 150
SYNC_DIST_LOGGING: True

# `contexts.py`
TOP_K: 6
VIEW: 5

# `cognition_graph_webtext.py`
# NUM_SEQUENCES_INTERPED is drawn from the other end of the same indices as
# NUM_SEQUENCES_EVALED in `collect_acts.py`.
MAX_SEQ_INTERPED_LEN: 100
SEQ_PER_DIM_CAP: 100
# NUM_SEQUENCES_INTERPED: 250

# `cognition_graph_mc.py`
# Currently, only NUM_QUESTIONS_INTERPED: 1 is really supported. Larger values
# are computational waste.
NUM_QUESTIONS_INTERPED: 1
MAX_NEW_TOKENS: 1
NUM_RETURN_SEQUENCES: 1
NUM_SHOT: 6
